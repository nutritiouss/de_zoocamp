{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00bc6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7cacea",
   "metadata": {},
   "source": [
    "### Question 1: \n",
    "\n",
    "**Install Spark and PySpark** \n",
    "\n",
    "- Install Spark\n",
    "- Run PySpark\n",
    "- Create a local spark session\n",
    "- Execute spark.version.\n",
    "\n",
    "What's the output?\n",
    "- **3.3.2**\n",
    "- 2.1.4\n",
    "- 1.2.3\n",
    "- 5.4\n",
    "</br></br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd4a0f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/12 17:14:36 WARN Utils: Your hostname, Vostro-14-5401 resolves to a loopback address: 127.0.1.1; using 192.168.1.115 instead (on interface wlp1s0)\n",
      "23/03/12 17:14:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/12 17:14:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/03/12 17:14:37 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/03/12 17:14:37 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/03/12 17:14:37 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "23/03/12 17:14:37 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "23/03/12 17:14:37 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3e4c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4e8a0",
   "metadata": {},
   "source": [
    "\n",
    "### Question 2: \n",
    "\n",
    "**HVFHW June 2021**\n",
    "\n",
    "Read it with Spark using the same schema as we did in the lessons.</br> \n",
    "We will use this dataset for all the remaining questions.</br>\n",
    "Repartition it to 12 partitions and save it to parquet.</br>\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches.</br>\n",
    "\n",
    "\n",
    "- 2MB\n",
    "- **24MB**\n",
    "- 100MB\n",
    "- 250MB\n",
    "</br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "421c457b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-12 17:19:10--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz\n",
      "Распознаётся github.com (github.com)… 140.82.121.3\n",
      "Подключение к github.com (github.com)|140.82.121.3|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 302 Found\n",
      "Адрес: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230312%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230312T141910Z&X-Amz-Expires=300&X-Amz-Signature=502b7d1638b2470b56f0c1e39dfa684fcf8d540dd73bc1c75577976bec4ff52f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream [переход]\n",
      "--2023-03-12 17:19:10--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/4564ad9e-a6da-4923-ad6f-35ff02446a51?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230312%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230312T141910Z&X-Amz-Expires=300&X-Amz-Signature=502b7d1638b2470b56f0c1e39dfa684fcf8d540dd73bc1c75577976bec4ff52f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhvhv_tripdata_2021-06.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Распознаётся objects.githubusercontent.com (objects.githubusercontent.com)… 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Подключение к objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... соединение установлено.\n",
      "HTTP-запрос отправлен. Ожидание ответа… 200 OK\n",
      "Длина: 175799316 (168M) [application/octet-stream]\n",
      "Сохранение в: «./data/raw/fhvhv/fhvhv_tripdata_2021-06.csv.gz»\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 167,66M  4,93MB/s    за 69s     \n",
      "\n",
      "2023-03-12 17:20:19 (2,44 MB/s) - «./data/raw/fhvhv/fhvhv_tripdata_2021-06.csv.gz» сохранён [175799316/175799316]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhvhv/fhvhv_tripdata_2021-06.csv.gz -P ./data/raw/fhvhv/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7216e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gzip -d ./data/raw/fhvhv/fhvhv_tripdata_2021-06.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5236cebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 tikhonov tikhonov 878M дек 20 03:13 ./data/raw/fhvhv/fhvhv_tripdata_2021-06.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./data/raw/fhvhv/fhvhv_tripdata_2021-06.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0a3399a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68bc8b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/12 20:35:13 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 7, schema size: 6\n",
      "CSV file: file:///opt/Python/de_zoocamp/week_5/oficial_repo/code/data/raw/fhvhv/fhvhv_tripdata_2021-06.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 63:===========================================>              (6 + 2) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/12 20:35:58 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 65:====>                                                    (1 + 8) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/12 20:36:04 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('data/raw/fhvhv/fhvhv_tripdata_2021-06.csv')\n",
    "\n",
    "df = df.repartition(12)\n",
    "\n",
    "df.write.parquet('data/pq/fhvhv/2021/06/',mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b6de80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "итого 262M\r\n",
      "drwxr-xr-x 2 tikhonov tikhonov 4,0K мар 12 20:36 .\r\n",
      "drwxr-xr-x 3 tikhonov tikhonov 4,0K мар 12 20:35 ..\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov  22M мар 12 20:36 part-00000-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov 173K мар 12 20:36 .part-00000-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet.crc\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov  22M мар 12 20:36 part-00001-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov 173K мар 12 20:36 .part-00001-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet.crc\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov  22M мар 12 20:36 part-00002-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov 173K мар 12 20:36 .part-00002-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet.crc\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov  22M мар 12 20:36 part-00003-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov 173K мар 12 20:36 .part-00003-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet.crc\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov  22M мар 12 20:36 part-00004-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov 173K мар 12 20:36 .part-00004-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet.crc\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov  22M мар 12 20:36 part-00005-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov 173K мар 12 20:36 .part-00005-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet.crc\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov  22M мар 12 20:36 part-00006-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov 173K мар 12 20:36 .part-00006-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet.crc\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov  22M мар 12 20:36 part-00007-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov 173K мар 12 20:36 .part-00007-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet.crc\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov  22M мар 12 20:36 part-00008-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov 173K мар 12 20:36 .part-00008-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet.crc\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov  22M мар 12 20:36 part-00009-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov 173K мар 12 20:36 .part-00009-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet.crc\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov  22M мар 12 20:36 part-00010-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov 173K мар 12 20:36 .part-00010-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet.crc\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov  22M мар 12 20:36 part-00011-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov 173K мар 12 20:36 .part-00011-5f29ac06-05c1-43a6-960a-a89169b72afa-c000.snappy.parquet.crc\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov    0 мар 12 20:36 _SUCCESS\r\n",
      "-rw-r--r-- 1 tikhonov tikhonov    8 мар 12 20:36 ._SUCCESS.crc\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah data/pq/fhvhv/2021/06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f664498",
   "metadata": {},
   "source": [
    "### Question 3: \n",
    "\n",
    "**Count records**  \n",
    "\n",
    "How many taxi trips were there on June 15?</br></br>\n",
    "Consider only trips that started on June 15.</br>\n",
    "\n",
    "- 308,164\n",
    "- 12,856\n",
    "- **452,470**\n",
    "- 50,982\n",
    "</br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "58989b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('data/pq/fhvhv/2021/06/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f7489aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6c2500fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452470"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .filter(\"pickup_date = '2021-06-15'\") \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dd7ae60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('fhvhv_2021_06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6d47c147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  452470|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    COUNT(1)\n",
    "FROM \n",
    "    fhvhv_2021_06\n",
    "WHERE\n",
    "    to_date(pickup_datetime) = '2021-06-15';\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13683677",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Question 4: \n",
    "\n",
    "**Longest trip for each day**  \n",
    "\n",
    "Now calculate the duration for each trip.</br>\n",
    "How long was the longest trip in Hours?</br>\n",
    "\n",
    "- **66.87 Hours**\n",
    "- 243.44 Hours\n",
    "- 7.68 Hours\n",
    "- 3.32 Hours\n",
    "</br></br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "805a05b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|              B02878|2021-06-02 17:32:38|2021-06-02 18:16:03|         237|         144|      N|\n",
      "|              B02765|2021-06-01 07:17:49|2021-06-01 07:47:22|         216|         139|      N|\n",
      "|              B02871|2021-06-02 22:05:37|2021-06-02 22:09:33|         256|         255|      N|\n",
      "|              B02872|2021-06-02 08:02:35|2021-06-02 08:09:48|          56|          82|      N|\n",
      "|              B02617|2021-06-02 15:49:50|2021-06-02 16:10:47|         100|         262|      N|\n",
      "|              B02878|2021-06-03 07:38:50|2021-06-03 08:12:16|         180|           7|      N|\n",
      "|              B02765|2021-06-01 01:35:09|2021-06-01 01:38:38|          63|         258|      N|\n",
      "|              B02510|2021-06-03 08:22:24|2021-06-03 08:35:08|          26|          22|      N|\n",
      "|              B02867|2021-06-01 16:32:19|2021-06-01 16:41:21|          79|         107|      N|\n",
      "|              B02510|2021-06-03 19:55:18|2021-06-03 20:09:14|          68|         164|      N|\n",
      "|              B02764|2021-06-04 07:12:27|2021-06-04 07:38:02|         178|         231|      N|\n",
      "|              B02510|2021-06-02 19:47:02|2021-06-02 20:08:47|         132|         265|      N|\n",
      "|              B02880|2021-06-01 17:25:50|2021-06-01 17:48:22|         244|          75|      N|\n",
      "|              B02510|2021-06-04 16:47:22|2021-06-04 16:58:09|         238|          75|      N|\n",
      "|              B02870|2021-06-01 02:01:17|2021-06-01 02:07:42|         220|         240|      N|\n",
      "|              B02764|2021-06-04 20:31:46|2021-06-04 20:35:00|         125|         158|      N|\n",
      "|              B02510|2021-06-01 08:43:33|2021-06-01 09:01:15|          82|         223|      N|\n",
      "|              B02510|2021-06-01 17:55:32|2021-06-01 18:28:33|         237|         261|      N|\n",
      "|              B02875|2021-06-01 22:34:57|2021-06-01 22:44:25|         114|         148|      N|\n",
      "|              B02876|2021-06-04 16:41:12|2021-06-04 16:54:23|         130|         205|      N|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b7f25b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 77:======================================>                  (8 + 4) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------------+\n",
      "|    pickup_datetime|   dropoff_datetime|     diff_in_hours|\n",
      "+-------------------+-------------------+------------------+\n",
      "|2021-06-25 13:55:41|2021-06-28 08:48:25|  66.8788888888889|\n",
      "|2021-06-22 12:09:45|2021-06-23 13:42:44|25.549722222222222|\n",
      "|2021-06-27 10:32:29|2021-06-28 06:31:20|19.980833333333333|\n",
      "|2021-06-26 22:37:11|2021-06-27 16:49:01|18.197222222222223|\n",
      "|2021-06-23 20:40:43|2021-06-24 13:08:44|16.466944444444444|\n",
      "|2021-06-23 22:03:31|2021-06-24 12:19:39|14.268888888888888|\n",
      "|2021-06-24 23:11:00|2021-06-25 13:05:35|13.909722222222221|\n",
      "|2021-06-04 20:56:02|2021-06-05 08:36:14|             11.67|\n",
      "|2021-06-27 07:45:19|2021-06-27 19:07:16|11.365833333333333|\n",
      "|2021-06-20 17:05:12|2021-06-21 04:04:16|10.984444444444444|\n",
      "+-------------------+-------------------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query_result = spark.sql(\"\"\"\n",
    "SELECT \n",
    "pickup_datetime, \n",
    "dropoff_datetime,\n",
    "((bigint(to_timestamp(dropoff_datetime)))-(bigint(to_timestamp(pickup_datetime))))/3600 AS diff_in_hours\n",
    "FROM fhvhv_2021_06\n",
    "ORDER BY 3 DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "query_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe84e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d915096b",
   "metadata": {},
   "source": [
    "### Question 5: \n",
    "\n",
    "**User Interface**\n",
    "\n",
    " Spark’s User Interface which shows application's dashboard runs on which local port?</br>\n",
    "\n",
    "- 80\n",
    "- 443\n",
    "- **4040**\n",
    "- 8080\n",
    "</br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7243d131",
   "metadata": {},
   "source": [
    "### Question 6: \n",
    "\n",
    "**Most frequent pickup location zone**\n",
    "\n",
    "Load the zone lookup data into a temp view in Spark</br>\n",
    "[Zone Data](https://github.com/DataTalksClub/nyc-tlc-data/releases/download/misc/taxi_zone_lookup.csv)</br>\n",
    "\n",
    "Using the zone lookup data and the fhvhv June 2021 data, what is the name of the most frequent pickup location zone?</br>\n",
    "\n",
    "- East Chelsea\n",
    "- Astoria\n",
    "- Union Sq\n",
    "- **Crown Heights North**\n",
    "</br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10173a",
   "metadata": {},
   "source": [
    "**Q6**: Most common locations pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "74b7f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.parquet('data/pq/zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "81642d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LocationID', 'Borough', 'Zone', 'service_zone']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4f460dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'SR_Flag']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ad8f0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.createOrReplaceTempView('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bc19f8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                Zone|count(1)|\n",
      "+--------------------+--------+\n",
      "| Crown Heights North|  231279|\n",
      "|        East Village|  221244|\n",
      "|         JFK Airport|  188867|\n",
      "|      Bushwick South|  187929|\n",
      "|       East New York|  186780|\n",
      "|TriBeCa/Civic Center|  164344|\n",
      "|   LaGuardia Airport|  161596|\n",
      "|            Union Sq|  158937|\n",
      "|        West Village|  154698|\n",
      "|             Astoria|  152493|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join = df.join(df_zones, (df['PULocationID'] == df_zones['LocationID']))\n",
    "\n",
    "df_join.createOrReplaceTempView(\"trips_joined\")\n",
    "\n",
    "query_result = spark.sql(\"\"\"\n",
    "SELECT Zone, COUNT(*)\n",
    "FROM trips_joined\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "query_result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
